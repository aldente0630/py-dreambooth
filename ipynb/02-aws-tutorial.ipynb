{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53811d2a-9013-4de2-8cd8-1ab80bccf133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b5bac-2d13-47cc-bcb5-f08ce8e531dd",
   "metadata": {},
   "source": [
    "# Using *Py-Dreambooth* with AWS Cloud Resources üßë‚Äçüíª\n",
    "* Use *Py-Dreambooth* to easily create AI avatar images from photos of you, your family, friends, or pets!\n",
    "* First, you need to set up your AWS configuration and credentials files. Refer to [this document](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html).\n",
    "* Additionally, by default, the `ml.g4dn.xlarge` processing job and endpoint deployment will run. If you don't have enough quota, please increase it.\n",
    "\n",
    "## Install the package\n",
    "* Install the *Py-Dreambooth* python package as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65afcca8-f239-4057-836d-011a7784f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q py-dreambooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38934d41-8e95-4d96-9bfb-74cd1ab69e3a",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "* There are several types of model classes, but you'll be using the most basic model, the Stable Diffusion Dreambooth LoRA model `SDDreamboothLoraModel`, but you don't need to worry about that right now. ü§∑‚Äç‚ôÇÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceea878-1858-41ae-bbc2-d41be276ab40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sys\n",
    "from py_dreambooth.dataset import AWSDataset\n",
    "from py_dreambooth.model import SdDreamboothLoraModel\n",
    "from py_dreambooth.predictor import AWSPredictor\n",
    "from py_dreambooth.trainer import AWSTrainer\n",
    "from py_dreambooth.utils.image_helpers import display_images\n",
    "from py_dreambooth.utils.prompt_helpers import make_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e0929-e89b-4b8e-835e-8d6666ad87f0",
   "metadata": {},
   "source": [
    "## Prepare your data üì∏\n",
    "* The boto3 session should be created appropriately for the AWS profile or access key information you set up previously. You'll use the default profile here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e17af-b416-4be1-a07f-7db6c4e24410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"  # the directory with photos for the model to train on \n",
    "\n",
    "boto_session = boto3.Session()\n",
    "dataset = AWSDataset(DATA_DIR, boto_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8789bee-719b-4bf3-bcd7-a41d39ad19b3",
   "metadata": {},
   "source": [
    "* Very important! In the `DATA_DIR` defined above, put the pictures (jpg or png) of the subject you want to train.\n",
    "* For this task, you'll need about 10 to 20 solo, high-quality selfies taken with different backgrounds, lighting, and facial expressions. I think a great example can be found in [Joe Penna's GitHub repository](https://github.com/JoePenna/Dreambooth-Stable-Diffusion).\n",
    "\n",
    "![Samples](../assets/asset-001.png)\n",
    "* Use the following image processing method to crop the images into a square centered on the face. If the subject the model is trying to learn is not a person (for example, a dog), set the `detect_face` argument to `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43780fef67ed87a8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.preprocess_images(detect_face=True)\n",
    "dataset = dataset.upload_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d2937-93a4-4320-954d-b4c352f35723",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train the model ü§ñ\n",
    "* Now it's time to train the model! Tell the model the name of the subject you want to train (e.g., Joe) and the class it belongs to. \n",
    "* When defining a model, one of the important arguments is how many iterations to train, or `max_train_steps`. It is generally accepted that 800 to 1200 steps are appropriate for a person, and 200 to 400 steps are appropriate for a non-human animal. The default value is 100 times the number of photos you have. You don't need to worry about that right now ü§∑‚Äç‚ôÇÔ∏è, but if you don't like the results of the generated image below, this is the first parameter to adjust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed850d-1d56-4369-80f0-bebcab0e3adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SUBJECT_NAME = \"sks\"  # The name of the subject you want to learn\n",
    "CLASS_NAME = \"person\"  # The class to which the subject you want to learn belongs\n",
    "\n",
    "model = SdDreamboothLoraModel(\n",
    "    subject_name=SUBJECT_NAME, \n",
    "    class_name=CLASS_NAME,\n",
    "    # max_train_steps=1000,\n",
    ")\n",
    "\n",
    "trainer = AWSTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f2a9a3-7cf0-455d-9948-ce96b861025e",
   "metadata": {},
   "source": [
    "* Model training time can be as short as a few tens of minutes or as long as several hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ed0c9-00f6-4b48-9324-5deaedcfc47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predictor = trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3e656-bdee-4762-8208-ea5fe80f6447",
   "metadata": {},
   "source": [
    "* If you restart the notebook kernel and then want to redeploy the models you've already trained to the endpoint, you can do so as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ea2bc-e066-4037-8fd8-42ed4fac131a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictor = AWSPredictor(model, dataset.get_s3_model_uri(), boto_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeea02e-dab1-4237-b3dd-e79e3f2e6cfc",
   "metadata": {},
   "source": [
    "## Create images as you wish! üíÉ\n",
    "* Use the prompts to create any image you like. The prompt text should contain the subject name and class name defined above.\n",
    "* Having trouble coming up with a good prompt? Don't worry. You can use the `make_prompt` function to generate a curated prompt at random. Check this out. üôÜ‚Äç‚ôÄÔ∏è\n",
    "* Creating great images takes patience. Play around with the prompts, but if the quality of the generation itself is problematic, you may need to retrain with better data and more appropriate training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ec891-6f71-4a26-8e90-5b0884ed4f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "prompt = f\"A photo of {SUBJECT_NAME} {CLASS_NAME} with Eiffel Tower in the background\"\n",
    "# prompt = next(make_prompt(SUBJECT_NAME, CLASS_NAME))\n",
    "\n",
    "print(f\"The prompt is as follows:\\n{prompt}\")\n",
    "\n",
    "images = predictor.predict(\n",
    "    prompt, height=768, width=512, num_images_per_prompt=2,\n",
    ")\n",
    "\n",
    "display_images(images, fig_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32398fab-f192-4c2b-8a50-fc4d74f89810",
   "metadata": {},
   "source": [
    "* Very important! Just having an AWS endpoint running to generate images is expensive. When you're done, be sure to delete the endpoint and check the console!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791984fc-4fa9-48b7-95c6-5b1c1264c4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
